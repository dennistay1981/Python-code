{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries and data"
      ],
      "metadata": {
        "id": "DWCPiL3_vxzk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Tpokj6hmvkSM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#for regression\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#for classification\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#for creating train-test dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data=pd.read_csv('Lecture7.csv',index_col='Country')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display all columns and rows"
      ],
      "metadata": {
        "id": "gm2UrS6L2RvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows',None)\n",
        "pd.set_option('display.max_columns',None)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "TNJUeBY02W3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating regression models"
      ],
      "metadata": {
        "id": "nd7MpEpW2cJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisit lecture 5 example, without train-test split\n",
        "\n",
        "#USING STATSMODELS\n",
        "model = ols('Happiness ~ Life_exp',data).fit()\n",
        "model.summary()\n",
        "\n",
        "#Generate happiness predictions\n",
        "data['Predicted_H'] = model.predict(data)\n",
        "\n",
        "#Evaluate accuracy with visualizations\n",
        "sns.scatterplot(data, y='Predicted_H', x='Happiness')\n",
        "plt.plot([min(data['Happiness']), max(data['Happiness'])], [min(data['Happiness']), max(data['Happiness'])], color='red')\n",
        "\n",
        "#Evaluate accuracy with MAPE\n",
        "mean_absolute_percentage_error(data['Happiness'], data['Predicted_H'])\n",
        "\n",
        "\n",
        "\n",
        "#USING SCIKIT-LEARN\n",
        "y=data[['Happiness']]\n",
        "x=data[['Life_exp']]\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)\n",
        "\n",
        "#Getting intercept and slope values\n",
        "model.intercept_\n",
        "model.coef_\n",
        "\n",
        "#Generate happiness predictions\n",
        "data['Predicted_H'] = model.predict(x)\n",
        "\n",
        "#R2 and MAPE\n",
        "r2_score(data['Happiness'], data['Predicted_H'])\n",
        "mean_absolute_percentage_error(data['Happiness'], data['Predicted_H'])\n"
      ],
      "metadata": {
        "id": "mQIO1L0i0B62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying TRAIN-TEST SPLIT"
      ],
      "metadata": {
        "id": "z3FQDhDg56oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define outcome and predictor(s) (same as above)\n",
        "y=data[['Happiness']]\n",
        "x=data[['Life_exp']]\n",
        "\n",
        "#Split x and y into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "len(x_train)\n",
        "len(x_test)\n",
        "\n",
        "\n",
        "#USING SCIKIT-LEARN\n",
        "#Train model on training data\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "#Getting intercept and slope values\n",
        "model.intercept_\n",
        "model.coef_\n",
        "\n",
        "\n",
        "#Evaluate model with TRAINING DATA\n",
        "model.predict(x_train)\n",
        "\n",
        "r2_score(y_train, model.predict(x_train))\n",
        "mean_absolute_percentage_error(y_train, model.predict(x_train))\n",
        "\n",
        "\n",
        "#Evaluate model with TESTING DATA\n",
        "model.predict(x_test)\n",
        "\n",
        "r2_score(y_test, model.predict(x_test))\n",
        "mean_absolute_percentage_error(y_test, model.predict(x_test))\n",
        "\n",
        "\n",
        "\n",
        "#USING STATSMODELS\n",
        "#recreate two separate dataframes, one of training and one of testing data only\n",
        "trainset=pd.concat([x_train, y_train], axis=1)  #axis=1 concats along columns, axis=0 concats along index\n",
        "testset=pd.concat([x_test, y_test], axis=1)\n",
        "\n",
        "\n",
        "#Train model on training dataset, and evaluate model with TRAINING DATA\n",
        "model = ols('Happiness ~ Life_exp',trainset).fit()\n",
        "model.summary()\n",
        "\n",
        "#Calculate MAPE\n",
        "model.predict(trainset)\n",
        "\n",
        "mean_absolute_percentage_error(trainset['Happiness'], model.predict(trainset))\n",
        "\n",
        "\n",
        "#Evaluate model with TESTING DATA\n",
        "model.predict(testset)\n",
        "\n",
        "r2_score(testset['Happiness'], model.predict(testset))\n",
        "mean_absolute_percentage_error(testset['Happiness'], model.predict(testset))\n"
      ],
      "metadata": {
        "id": "1ZrcTys558Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating classification models"
      ],
      "metadata": {
        "id": "6pWz7V1L6RP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define outcome and predictor(s)\n",
        "y = data['Regime']\n",
        "x = data[['Happiness','GDP_log']]\n",
        "\n",
        "#Revisit lecture 6 example, without train-test split\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(x,y)\n",
        "knn.score(x, y)\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(data['Regime'], knn.predict(x))\n",
        "\n",
        "labels = data['Regime'].unique()\n",
        "\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"Blues\", yticklabels=labels, xticklabels=labels, annot_kws={\"size\": 20})\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "#Split x and y into train and test sets, with stratify=y\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#Train k-nn model on training data with k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train,y_train)\n",
        "\n",
        "#Evaluate model with TRAINING DATA\n",
        "knn.score(x_train,y_train)\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_train, knn.predict(x_train))\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"Blues\", yticklabels=labels, xticklabels=labels, annot_kws={\"size\": 20})\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "\n",
        "#Evaluate model with TESTING DATA\n",
        "knn.score(x_test,y_test)\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, knn.predict(x_test))\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"Blues\", yticklabels=labels, xticklabels=labels, annot_kws={\"size\": 20})\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n"
      ],
      "metadata": {
        "id": "1EVjQmQ26Xln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-folds cross validation"
      ],
      "metadata": {
        "id": "-mPLW2Ym6hDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# Compute 5-fold cross-validation scores for regression model\n",
        "y=data[['Happiness']]\n",
        "x=data[['Life_exp']]\n",
        "model = LinearRegression()\n",
        "\n",
        "cv_scores = cross_val_score(model,x, y, cv=5, scoring='r2')  #5 folds, specify r2 as metric\n",
        "np.mean(cv_scores)\n",
        "\n",
        "\n",
        "# Compute 5-fold cross-validation scores for classification model\n",
        "y = data['Regime']\n",
        "x = data[['Happiness','GDP_log']]\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "cv_scores = cross_val_score(knn, x, y, cv=5, scoring='accuracy')  #5 folds, specify accuracy as metric\n",
        "np.mean(cv_scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "CjbIHUqD6jYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually RESAMPLING different train-test sets"
      ],
      "metadata": {
        "id": "3C0mj1sP6mw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For regression\n",
        "y=data[['Happiness']]\n",
        "x=data[['Life_exp']]\n",
        "model = LinearRegression()\n",
        "\n",
        "r2s =[] #create lists to store the various scores of different combinations\n",
        "mapes =[]\n",
        "\n",
        "for i in range (100):\n",
        "    #remove random_state because we now want a different training set each time\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "    model.fit(x_train,y_train)\n",
        "    r2s.append(r2_score(y_test,model.predict(x_test)))\n",
        "    mapes.append(mean_absolute_percentage_error(y_test,model.predict(x_test)))\n",
        "\n",
        "#compile the two lists into df for further analysis\n",
        "df = pd.DataFrame({'R2': r2s, 'MAPE': mapes})\n",
        "df.mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#For classification\n",
        "y = data['Regime']\n",
        "x = data[['Happiness','GDP_log']]\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "accuracy=[]\n",
        "\n",
        "for i in range (100):\n",
        "    #remove random_state because we now want a different training set each time\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify=y)\n",
        "    knn.fit(x_train,y_train)\n",
        "    accuracy.append(knn.score(x_test,y_test))\n",
        "\n",
        "#compile the list into df for further analysis\n",
        "df = pd.DataFrame(accuracy, columns=['accuracy'])\n",
        "df.mean()\n"
      ],
      "metadata": {
        "id": "ei5s2szu6ulx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEMINAR 7"
      ],
      "metadata": {
        "id": "KlQN2pkh68JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('Lecture7.csv',index_col='Country')\n",
        "y = data['Regime']\n",
        "x = data[['Happiness','GDP_log']]\n",
        "\n",
        "\n",
        "# Setup arrays to store accuracy values\n",
        "neighbors = np.arange(1, 16)\n",
        "train_accuracy = np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "average_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "# Create training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Loop over different values of k, fit model, and compute accuracy\n",
        "for i, k in enumerate(neighbors):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(x_train,y_train)\n",
        "    train_accuracy[i] = knn.score(x_train,y_train)\n",
        "    test_accuracy[i] = knn.score(x_test,y_test)\n",
        "    average_accuracy[i] = (train_accuracy[i] + test_accuracy[i]) / 2\n",
        "\n",
        "# Generate plot\n",
        "plt.title('k-NN: Varying Number of Neighbors')\n",
        "plt.plot(neighbors, train_accuracy, label='train accuracy')\n",
        "plt.plot(neighbors, test_accuracy, label='test accuracy')\n",
        "plt.plot(neighbors, average_accuracy, label='avg accuracy')\n",
        "plt.xticks(neighbors)\n",
        "plt.xlabel('Number of Neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ixpICcsM6Uci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}